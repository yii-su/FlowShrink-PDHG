import os
import sys

import torch
import torch._dynamo
import numpy as np
from scipy.sparse import coo_matrix
import time

import FlowShrink.utils as utils
import FlowShrink.shortest_paths_gpu as ws

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
torch._dynamo.config.suppress_errors = True  # type: ignore # é¿å…ä¸€äº›æ— å…³è­¦å‘Š


class MCNFPDHGWARMSTART:
    def __init__(self, dtype=torch.float64):
        self.device = torch.device("cuda:0")
        self.dtype = dtype
        self.weight_update_scaling=torch.tensor(0.5,device=self.device)
        self.best_rp=torch.tensor(torch.inf,device=self.device)
        self.best_rd=torch.tensor(torch.inf,device=self.device)
        

    def create_data(self, num_nodes, k, num_commodities, seed=1):
        self.N = num_nodes
        self.K = num_commodities
        device = self.device
        dtype = self.dtype
        if dtype == torch.float64:
            npdtype = np.float64
        else:
            npdtype = np.float32

        # adjacency and incidence
        W_adj = utils.create_base_network(self.N, k, seed)
        W_adj = utils.ensure_weak_connectivity(W_adj, seed)
        A_inc_np, p_np = utils.adjacency_to_incidence(W_adj)  # (N, M)
        commodities = utils.create_commodities(W_adj, self.K, 10.0, seed)
        self.W_adj = torch.tensor(W_adj, dtype=dtype, device=device)
        del W_adj

        # capacities
        c_np = utils.generate_capacity_constraints(
            A_inc_np, commodities, 1.0, 5.0, seed=seed
        )
        self.c = torch.from_numpy(c_np.astype(npdtype)).to(self.device)
        A_inc = torch.from_numpy(A_inc_np)
        del A_inc_np
        """
        torch.where(condition) åœ¨å¤„ç†äºŒç»´å¼ é‡æ—¶ï¼Œè¿”å›çš„ç´¢å¼•æ˜¯æŒ‰ç…§ Row-Majorï¼ˆè¡Œä¼˜å…ˆï¼‰ é¡ºåºæ’åˆ—çš„ï¼Œå³å…ˆæ‰«æç¬¬0è¡Œï¼Œå†æ‰«æç¬¬1è¡Œï¼Œä»¥æ­¤ç±»æ¨ã€‚
        ç„¶è€Œï¼Œä½ çš„ cï¼ˆå®¹é‡ï¼‰ã€pï¼ˆè´¹ç”¨ï¼‰ä»¥åŠå˜é‡ x éƒ½æ˜¯æŒ‰ç…§ Edge Indexï¼ˆåˆ—ç´¢å¼• 0 åˆ° M-1ï¼‰ æ’åˆ—çš„ã€‚
        ä½ çš„å‡è®¾ï¼šedges_src[j] å¯¹åº”ç¬¬ j æ¡è¾¹ï¼ˆå³ A_inc çš„ç¬¬ j åˆ—ï¼‰çš„æºèŠ‚ç‚¹ã€‚
        å®é™…æƒ…å†µï¼šedges_src åªæ˜¯åŒ…å«äº†æ‰€æœ‰æºèŠ‚ç‚¹çš„åˆ—è¡¨ï¼Œä½†æŒ‰ç…§èŠ‚ç‚¹IDæ’åºï¼ˆå—è¡Œæ‰«æé¡ºåºå½±å“ï¼‰ï¼Œå®Œå…¨æ‰“ä¹±äº†ä¸è¾¹ç´¢å¼• 0...M-1 çš„å¯¹åº”å…³ç³»ã€‚ 
        å®é™…å˜æˆäº†æ²¿ç€dim=1å¯»æ‰¾ 
        åæœï¼š
        PDHG æ±‚è§£å™¨å®é™…ä¸Šæ˜¯åœ¨ä¸€ä¸ª ä¹±è¿çº¿çš„å›¾ ä¸Šè¿›è¡Œä¼˜åŒ–ã€‚è¾¹çš„èµ·ç‚¹å’Œç»ˆç‚¹è¢«é‡æ–°æ´—ç‰Œäº†ï¼Œä½†è¾¹çš„å®¹é‡å’Œè´¹ç”¨å´ä¿æŒåŸåºã€‚     
        """
        # self.edges_src=torch.where(A_inc==-1)[0].to(device)# M
        # self.edges_dst=torch.where(A_inc==1)[0].to(device)# M

        # argmin æ‰¾åˆ°æ¯åˆ—æœ€å°å€¼çš„ç´¢å¼•ï¼ˆå³ -1 æ‰€åœ¨çš„è¡Œç´¢å¼•ï¼‰
        self.edges_src = torch.argmin(A_inc, dim=0).to(device)
        # argmax æ‰¾åˆ°æ¯åˆ—æœ€å¤§å€¼çš„ç´¢å¼•ï¼ˆå³ 1 æ‰€åœ¨çš„è¡Œç´¢å¼•ï¼‰
        self.edges_dst = torch.argmax(A_inc, dim=0).to(device)
        self.M = A_inc.shape[1]
        del A_inc

        # edge cost
        p = torch.from_numpy(p_np.astype(npdtype)).to(self.device)
        del p_np

        # W, d
        W_scale = 300.0
        # self.Wå·²ç»ä¹˜äº†W_scale
        self.W = (
            torch.from_numpy(
                utils.generate_weight(self.K, dimtype="vector", seed=seed) * W_scale
            )
            .to(self.device)
            .to(dtype)
        )
        commodity_src = [c[0] for c in commodities]
        commodity_dst = [c[1] for c in commodities]
        demands = [c[2] for c in commodities]
        self.d = torch.tensor(demands, dtype=dtype, device=self.device)
        # tensors used as indices must be long, int, byte or bool tensors
        self.k_src = torch.tensor(commodity_src, dtype=torch.long, device=self.device)
        self.k_dst = torch.tensor(commodity_dst, dtype=torch.long, device=self.device)
        del commodity_src, commodity_dst, demands, W_scale

        # keep p (M) on device
        self.p = p

        # f_mat (N,K) small-ish dense (-1,0,1)
        f_list = []
        for kk in range(self.K):
            f_np = np.zeros(self.N, dtype=npdtype)
            s_idx, t_idx = commodities[kk][0], commodities[kk][1]
            f_np[s_idx] = -1.0
            f_np[t_idx] = 1.0
            f_list.append(torch.from_numpy(f_np))
        self.f_mat = torch.stack(f_list, dim=1).to(self.device)

        return self.N, self.M

    def pdhg_step_fn(
        self, x_prev, X_prev, Y, x_bar, X_bar, sigma, tau, K, M, overrelax_rho
    ):
        # dual update,explicit,prox is here
        Y_new = Y + sigma * (self.A_matvec(x_bar) - self.S_matvec(X_bar))

        # primal update
        v = (x_prev - tau * self.AT_matvec(Y_new)).reshape(
            M, K
        ) - tau * self.p.unsqueeze(1)
        # x update as projection
        x_new = self.proj(v, self.c)
        # X update as proximal operator
        X_new = self.f1_prox(X_prev + tau * self.ST_matvec(Y_new), tau)

        # overrelaxation
        x_bar = (1 + overrelax_rho) * x_new - overrelax_rho * x_prev
        X_bar = (1 + overrelax_rho) * X_new - overrelax_rho * X_prev

        return x_new, X_new, Y_new, x_bar, X_bar

    # -------------------------
    # çŸ©é˜µ-å‘é‡æ¥å£ï¼ˆç¨€ç–åŒ–ï¼‰
    # -------------------------
    def A_matvec(self, x):
        flow = x.view(self.M, self.K)
        # åˆå§‹åŒ–ç»“æœ (N, K)
        div = torch.zeros((self.N, self.K), device=x.device, dtype=x.dtype)
        div.index_add_(0, self.edges_dst, flow)
        div.index_add_(0, self.edges_src, -flow)

        return div.reshape(self.N * self.K)

    def AT_matvec(self, y):
        potentials = y.view(self.N, self.K)
        # tension: (M, K)
        tension = potentials[self.edges_dst] - potentials[self.edges_src]

        return tension.reshape(self.M * self.K)

    def S_matvec(self, X):
        K, N = self.K, self.N
        # pytorchçš„å¹¿æ’­æœºåˆ¶ç”¨äºæ ‡é‡*å‘é‡æ—¶ï¼š
        # f_matä¸ºNÃ—KçŸ©é˜µï¼Œæ­¤å¤„æ“ä½œåº”ä¸ºå¯¹f_matçš„æ¯ä¸€åˆ—ï¼Œç”¨æ ‡é‡X_kå»ä¹˜
        # æ­£ç¡®æ–¹æ³•åº”ä¸ºå°†Xå¹¿æ’­ä¸º1è¡ŒKåˆ—ï¼Œå¯¹åº”f_matçš„Kåˆ—ï¼Œæ¯ä¸€åˆ—ä¸€ä¸ªæ ‡é‡ä¸è¯¥åˆ—åšä¹˜æ³•ï¼ˆåˆ—çº¿æ€§å˜æ¢ï¼‰ï¼Œå³X_col = X.unsqueeze(0)
        # æˆ–ç›´æ¥çœç•¥unsqueezeï¼Œè¿ç®—ç¬¦*ä¼šè§¦å‘pytorchçš„è‡ªåŠ¨æ ‡é‡ä¹˜å¹¿æ’­
        # æ­¤å¤„X_col = X.unsqueeze(1)æ²¡æœ‰æŠ¥é”™ï¼Œæ˜¯å› ä¸ºæµ‹è¯•æ•°æ®ä¸­N==Kï¼Œæ©ç›–äº†ç»´åº¦çš„ä¸åŒ¹é…
        blocks = self.f_mat * X  # N x K
        return blocks.reshape(N * K)

    def ST_matvec(self, Y):
        K, N = self.K, self.N
        Y_mat = Y.view(N, K)
        return torch.sum(self.f_mat * Y_mat, dim=0)

    def power_iteration_K_norm(self, iters=50):
        """
        Compute ||K||_2 where K = [A  -S].
        A here is mathcal(A), the linear operator in PDHG, not the adjacent or incidence matrix of the graph
        """
        dtype = self.dtype
        device = self.device
        u = torch.randn(self.K * self.M, device=device, dtype=dtype)  # MK
        v = torch.randn(self.K, device=device, dtype=dtype)  # K
        uv = torch.cat([u, v], dim=0)
        uv = uv / uv.norm()  # MK+K

        for _ in range(iters):
            u, v = torch.split(uv, self.K * self.M)
            # K [u; v] = ğ“(u) - S(v),KN
            Kuv = self.A_matvec(u) - self.S_matvec(v)

            # Káµ€(K[u;v])
            # Káµ€ y = [ğ“áµ€ y ; -Sáµ€ y]
            KT_K_u = self.AT_matvec(Kuv)  # KM=KM*KN * KN
            KT_K_v = -self.ST_matvec(Kuv)  # K=K*KN * KN

            uv_next = torch.cat([KT_K_u, KT_K_v], dim=0)
            norm_next = uv_next.norm()
            uv = uv_next / norm_next  # (M+1)*K

        # sqrt of eigenvalue of Káµ€K
        K_norm = norm_next.sqrt()
        return K_norm

    # -------------------------
    # PDHG solver with automated tau/sigma tuning and relaxation theta
    # -------------------------
    def pdhg_solve(
        self,
        x0,
        X0,
        Y0,
        tau=None,
        sigma=None,
        max_iter=200000,
        tol=1e-2,
        verbose=True,
        overrelax_rho=1.0,
        check_interval=500,
    ):
        dev = self.device
        x = x0.to(dev)
        X = X0.to(dev)
        
        # ensure data on device
        self.p = self.p.to(dev)
        self.c = self.c.to(dev)
        self.d = self.d.to(dev)
        self.W = self.W.to(dev)
        self.f_mat = self.f_mat.to(dev)

        # calculate the 2-norm of linear operator in our problem formulation to ensure convergence
        K_norm = self.power_iteration_K_norm()
        eta = 0.9 / K_norm  # safer estimation, K_norm is derived by iteration
        pweight = torch.tensor(1.0)
        tau = eta / pweight
        sigma = eta * pweight

        Y = Y0.to(dev).clone()
        x_prev = x.clone()
        X_prev = X.clone()
        x_bar = x.clone()
        X_bar = X.clone()

        if dev.type == "cuda":
            torch.cuda.synchronize()
        t0 = time.time()

        for it in range(max_iter):
            x_new, X_new, Y_new, x_bar, X_bar = self.pdhg_step_fn(
                x_prev,
                X_prev,
                Y,
                x_bar,
                X_bar,
                sigma,
                tau,
                self.K,
                self.M,
                overrelax_rho,
            )

            if it == max_iter - 1:
                print(f"Max iterations reached, r_p={r_primal:.2e}, r_d={r_dual:.2e}")  # noqa: F821

            if it % check_interval == 0:
                # residuals
                with torch.no_grad():
                    r_primal = torch.norm(self.A_matvec(x_bar) - self.S_matvec(X_bar))
                    r_dual = (
                        torch.norm(x_new - x_prev) / tau
                        + torch.norm(X_new - X_prev) / tau
                    )
                    tau, sigma, pweight = self.weight_update(
                        r_primal, r_dual, pweight, eta, tau
                    )
                    rp_val = r_primal.item()
                    rd_val = r_dual.item()

                if verbose:
                    print(
                        f"Iter {it:6d} | r_p={r_primal:.2e} | r_d={r_dual:.2e} | pweight={pweight}"
                    )

                if (rp_val < tol) and (rd_val < tol):
                    print(
                        f"Converged at iter {it}, r_p={r_primal:.2e}, r_d={r_dual:.2e}"
                    )
                    break

            # shift iteration
            x_prev, X_prev = x_new, X_new
            Y = Y_new

        if dev.type == "cuda":
            torch.cuda.synchronize()
        if verbose:
            print("PDHG total time:", time.time() - t0)
        return x_new, X_new, Y_new


    def weight_update(self, r_primal, r_dual, pweight, eta, tau):
        # cond_rp=r_primal>self.best_rp
        # cond_rd=r_dual>self.best_rd
        # cond_residual=cond_rp | cond_rd
        # eta_new=torch.where(cond_residual,eta*0.9,eta)
        # self.best_rp=torch.where(cond_rp,self.best_rp,r_primal)
        # self.best_rd=torch.where(cond_rd,self.best_rd,r_dual)
        scaling = self.weight_update_scaling  # theta
        ratio = r_primal / (r_dual + 1e-12)
        log_p = torch.log(pweight)
        cond1 = ratio > 2.0
        cond2 = ratio < 0.5
        change = torch.where(
            cond1,
            scaling,
            torch.where(cond2, -scaling, torch.tensor(0.0, device=self.device)),
        )
        pweight_new = torch.exp(log_p + change)
        pweight_new = torch.clamp(pweight_new, 1e-5, 1e5)
        tau = eta / pweight_new
        sigma = eta * pweight_new
        return tau, sigma, pweight_new#,eta_new

    # -------------------------
    # prox functions
    # -------------------------
    def f1_prox(self, X_tilde, tau):
        return (X_tilde + 2.0 * tau * self.W * self.d) / (1.0 + 2.0 * tau * self.W)

    def proj(self, U, c):
        """
        Active Set ç­–ç•¥ï¼šåªå¯¹è¿åå®¹é‡çº¦æŸçš„è¡Œè¿›è¡Œ Sort å’Œç²¾ç¡®æŠ•å½±ã€‚
        ä¿æŒäº†æ•°å­¦çš„ç²¾ç¡®æ€§ï¼ˆæ”¶æ•›å¿«ï¼‰ï¼ŒåŒæ—¶é¿å…äº†å¤§é‡çš„æ— æ•ˆè®¡ç®—ï¼ˆé€Ÿåº¦å¿«ï¼‰ã€‚
        """
        # 1. åŸºç¡€å¤„ç†ï¼šä»»ä½•æµé‡ä¸èƒ½ä¸ºè´Ÿ
        # è¿™é‡Œçš„ U è¿˜æ˜¯ (M, K)
        U_clamped = torch.clamp(U, min=0.0)

        # 2. è®¡ç®—æ¯æ¡è¾¹çš„æ€»æµé‡
        row_sum = U_clamped.sum(dim=1)

        # 3. æ‰¾å‡ºâ€œåè¾¹â€ï¼ˆActive Constraintsï¼‰ï¼šæ€»æµé‡è¶…è¿‡å®¹é‡ c çš„è¾¹
        # c æ˜¯ (M,)
        mask = row_sum > c

        # --- å¿«é€Ÿè·¯å¾„ ---
        # å¦‚æœæ²¡æœ‰ä»»ä½•è¾¹æ‹¥å µï¼Œç›´æ¥è¿”å›ï¼ˆè¿™åœ¨è¿­ä»£åˆæœŸéå¸¸å¸¸è§ï¼‰
        if not mask.any():
            return U_clamped.reshape(self.M * self.K)

        # --- æ…¢é€Ÿè·¯å¾„ï¼ˆåªé’ˆå¯¹åè¾¹ï¼‰ ---
        # æå–åè¾¹çš„å®¹é‡å’Œæµé‡
        # c_active: (N_active, )
        # U_active: (N_active, K)
        c_active = c[mask]
        U_active = U_clamped[mask]

        # *** æ ¸å¿ƒä¼˜åŒ–ï¼šåªå¯¹ mask é€‰å‡ºæ¥çš„è¿™éƒ¨åˆ†æ•°æ®è¿›è¡Œ Sort ***
        # è¿™é‡Œçš„è®¡ç®—é‡ä» M * K log K é™åˆ°äº† N_active * K log K
        U_sorted, _ = torch.sort(U_active, dim=1, descending=True)

        # --- ä¸‹é¢æ˜¯æ ‡å‡†çš„å•çº¯å½¢æŠ•å½±é€»è¾‘ (Simplex Projection) ---

        # è®¡ç®—å‰ç¼€å’Œ cumsum
        cssv = torch.cumsum(U_sorted, dim=1) - c_active.unsqueeze(1)

        # ç”Ÿæˆå¯¹åº”çš„é™¤æ•° range: [1, 2, 3, ..., K]
        # æ³¨æ„ï¼šä¸ºäº†é˜²æ­¢ shape å¹¿æ’­é”™è¯¯ï¼Œä¸€å®šè¦æ³¨æ„ç»´åº¦
        arange_k = torch.arange(1, self.K + 1, device=U.device, dtype=U.dtype)

        # è®¡ç®— rho çš„å€™é€‰å€¼
        cond = U_sorted - cssv / arange_k > 0.0

        # æ‰¾åˆ°æ»¡è¶³æ¡ä»¶çš„æœ€å¤§ç´¢å¼• rho
        # cond æ˜¯ boolï¼Œè½¬ float ç®— sum å¾—åˆ°æ»¡è¶³æ¡ä»¶çš„ä¸ªæ•°ï¼Œå‡ 1 å¾—åˆ°ä¸‹æ ‡
        rho = cond.sum(dim=1, keepdim=True).long() - 1

        # è·å–å¯¹åº”çš„ theta (é˜ˆå€¼)
        # gather ç”¨äºä» active çš„ cssv ä¸­å–å¯¹åº” rho ä½ç½®çš„å€¼
        theta = torch.gather(cssv, 1, rho) / (rho.float() + 1)

        # æ‰§è¡ŒæŠ•å½±ï¼šw = max(u - theta, 0)
        w_active = torch.clamp(U_active - theta, min=0.0)

        # --- ç»“æœå†™å› ---
        # å°†è®¡ç®—å¥½çš„æ‹¥å µè¾¹æŠ•å½±ç»“æœå†™å›å¤§çŸ©é˜µ
        # Clone æ˜¯ä¸ºäº†ä¸ç ´ååŸè®¡ç®—å›¾çš„ Leafï¼ˆè§†å…·ä½“ Autograd éœ€æ±‚ï¼Œä½†åœ¨ PDHG è¿™ç§ volatile ä¸Šä¸‹æ–‡ä¸­é€šå¸¸æ˜¯å®‰å…¨çš„ï¼‰
        U_out = U_clamped.clone()
        U_out[mask] = w_active

        return U_out.reshape(self.M * self.K)

    def make_initials(self, warm_start=True):
        # 0. åŸºç¡€å…¨é›¶åˆå§‹åŒ– (ä»¥é˜² W_adj æœªå‡†å¤‡å¥½)
        if self.W_adj is None and warm_start:
            print("Warning: W_adj is None, falling back to cold start.")
            return self._generate_cold_start()

        # 1. æ ¹æ®æ¨¡å¼åˆ†å‘
        if warm_start:
            # return self._generate_warm_start()
            return self._generate_mwu_warm_start()
        else:
            return self._generate_cold_start()

    def _generate_warm_start(self):
        """
        æœ€æ–°çš„ Warm Start ç­–ç•¥ï¼š
        x, X: Greedy Capacity Filling (è€ƒè™‘å®¹é‡é™åˆ¶)
        Y: Cost-to-Go Potential (æœ€çŸ­è·¯è·ç¦»)
        """
        device = self.device
        dtype = self.dtype
        K, M, N = self.K, self.M, self.N
        k_src, k_dst = self.k_src, self.k_dst
        demands, capacities = self.d, self.c
        weights = self.W

        # --- APSP ---
        # D, P, _ = ws.apsp_gpu(self.W_adj, dtype=dtype)
        D, P, _ = ws.parallel_bellman_ford_gpu(self.W_adj, dtype=dtype) # ä¼˜åŒ–è¿‡çš„ apsp_gpuï¼Œä¹‹åéƒ½é‡‡ç”¨è¿™ä¸ª
        del self.W_adj
        self.W_adj = None

        # --- è·¯å¾„è¿½è¸ª ---
        edge_lookup = torch.full((N, N), -1, dtype=torch.long, device=device)
        edge_lookup[self.edges_src, self.edges_dst] = torch.arange(M, device=device)

        x_flow = torch.zeros((M, K), dtype=dtype, device=device)
        curr_nodes = k_src.clone()
        active_mask = torch.ones(K, dtype=torch.bool, device=device)

        for _ in range(N):
            arrived = curr_nodes == k_dst
            active_mask = active_mask & (~arrived)
            if not active_mask.any():
                break

            next_nodes = P[curr_nodes, k_dst]
            edge_ids = edge_lookup[curr_nodes, next_nodes]
            valid_step = active_mask & (edge_ids != -1)
            
            if not valid_step.any():
                break

            valid_k = torch.nonzero(valid_step, as_tuple=True)[0]
            valid_e = edge_ids[valid_step]
            x_flow[valid_e, valid_k] = demands[valid_step]
            curr_nodes[valid_step] = next_nodes[valid_step]

        # --- Greedy Capacity Filling ---
        sorted_indices = torch.argsort(weights, descending=True)
        inv_sorted_indices = torch.argsort(sorted_indices)

        x_sorted = x_flow[:, sorted_indices]
        d_sorted = demands[sorted_indices]

        cum_flow = torch.cumsum(x_sorted, dim=1)
        prev_flow = cum_flow - x_sorted
        
        caps_expanded = capacities.view(-1, 1)
        residual_caps = (caps_expanded - prev_flow).clamp(min=0)
        allowed_flow_edge = torch.min(x_sorted, residual_caps)

        epsilon = 1e-6
        ratios_edge = allowed_flow_edge / (x_sorted + epsilon)
        path_mask = x_sorted > epsilon
        ratios_edge[~path_mask] = 1.0

        path_bottleneck_ratios, _ = torch.min(ratios_edge, dim=0)

        final_ratios = path_bottleneck_ratios[inv_sorted_indices]
        x_final = x_flow * final_ratios.view(1, -1)
        X_final = demands * final_ratios

        # --- Dual Y (Distance) ---
        Y_matrix = D[:, k_dst]
        finite_mask = torch.isfinite(Y_matrix)
        if finite_mask.any():
            max_val = Y_matrix[finite_mask].max()
            Y_matrix = torch.where(finite_mask, Y_matrix, max_val * 2.0)
        else:
            Y_matrix = torch.zeros_like(Y_matrix)

        return x_final.reshape(-1)*0.8, X_final*0.8, Y_matrix.reshape(-1)

    def _generate_cold_start(self):
        """
        æ—§çš„ Cold Start ç­–ç•¥ (å¤åˆ»)ï¼š
        å¯¹åº”åŸä»£ç ä¸­ x0=None, X0=None çš„æƒ…å†µã€‚
        ä¸è¿è¡Œ APSPï¼Œä¸è¿›è¡Œè·¯å¾„è¿½è¸ªã€‚
        
        é€»è¾‘ï¼š
        x0 = 0
        X0 = 0
        Y0 = -kappa * (A(x0) - S(X0)) => 0
        """
        device = self.device
        dtype = self.dtype
        
        # 1. åˆå§‹åŒ– x0 (å…¨0)
        x0 = torch.zeros(self.M * self.K, device=device, dtype=dtype)
        
        # 2. åˆå§‹åŒ– X0 (å…¨0)
        X0 = torch.zeros(self.K, device=device, dtype=dtype)
        
        # 3. åˆå§‹åŒ– Y0
        # å¯¹åº”æ—§ä»£ç  pdhg_solve ä¸­çš„: rY = self.A_matvec(x) - self.S_matvec(X)
        # å› ä¸º x=0, X=0ï¼Œæ‰€ä»¥ rY=0ï¼Œè¿›è€Œ Y=0ã€‚
        # Y çš„ç»´åº¦æ˜¯èŠ‚ç‚¹æ•° N * å•†å“æ•° K
        Y0 = torch.zeros(self.N * self.K, device=device, dtype=dtype)

        return x0, X0, Y0


    # def _generate_mwu_warm_start(self, batches=10):
    #     device = self.device
    #     dtype = self.dtype
    #     K, M, N = self.K, self.M, self.N
        
    #     # åŸºç¡€æ•°æ®
    #     k_src, k_dst = self.k_src, self.k_dst
    #     demands, capacities = self.d, self.c
    #     base_cost = self.p 
        
    #     x_total = torch.zeros((M, K), dtype=dtype, device=device)
    #     current_edge_weights = base_cost.clone()
    #     chunk_demands = demands / batches

    #     # Edge lookup: (N, N) -> edge_index
    #     edge_lookup = torch.full((N, N), -1, dtype=torch.long, device=device)
    #     edge_lookup[self.edges_src, self.edges_dst] = torch.arange(M, device=device)

    #     adj_matrix = torch.full((N, N), float('inf'), dtype=dtype, device=device)
    #     adj_matrix.fill_diagonal_(0.0)

    #     last_D = None

    #     if self.W_adj is not None:
    #         del self.W_adj
    #         self.W_adj = None

    #     for b in range(batches):
    #         # A. é‡å»ºé‚»æ¥çŸ©é˜µ
    #         adj_matrix.fill_(float('inf'))
    #         adj_matrix.fill_diagonal_(0.0)
    #         adj_matrix[self.edges_src, self.edges_dst] = current_edge_weights

    #         # B. è¿è¡Œ APSP 
    #         # å‡è®¾ ws.parallel_bellman_ford_gpu è¿”å› (Dist, Predecessors, _)
    #         # P[i, j] è¡¨ç¤ºä» i åˆ° j çš„è·¯å¾„ä¸Šï¼Œj çš„å‰é©±èŠ‚ç‚¹
    #         D, P, _ = ws.parallel_bellman_ford_gpu(adj_matrix, dtype=dtype)
    #         last_D = D

    #         # C. è·¯å¾„è¿½è¸ª (åå‘å›æº¯: DST -> SRC)
    #         x_batch = torch.zeros((M, K), dtype=dtype, device=device)
            
    #         # å½“å‰è¿½è¸ªèŠ‚ç‚¹åˆå§‹åŒ–ä¸ºç›®çš„åœ°
    #         curr_nodes = k_dst.clone() 
    #         active_mask = torch.ones(K, dtype=torch.bool, device=device)

    #         # æœ€é•¿è·¯å¾„ä¸è¶…è¿‡ N
    #         for _ in range(N):
    #             # å¦‚æœå½“å‰èŠ‚ç‚¹å·²ç»å›æº¯åˆ°äº†æºèŠ‚ç‚¹ï¼Œåˆ™åœæ­¢è¯¥ commodity
    #             arrived = (curr_nodes == k_src)
    #             active_mask = active_mask & (~arrived)
                
    #             if not active_mask.any():
    #                 break
                
    #             # æŸ¥æ‰¾å‰é©±èŠ‚ç‚¹
    #             # æˆ‘ä»¬éœ€è¦è·¯å¾„ k_src -> ... -> prev -> curr -> ... -> k_dst
    #             # P[src, dst] ç»™å‡ºçš„æ˜¯ dst çš„å‰é©±
    #             # è¿™é‡Œ src æ˜¯ k_src (æ¯ä¸ª commodity ä¸åŒ), dst æ˜¯å½“å‰å›æº¯åˆ°çš„èŠ‚ç‚¹ curr_nodes
    #             # åˆ©ç”¨ PyTorch çš„é«˜çº§ç´¢å¼• P[rows, cols]
    #             prev_nodes = P[k_src, curr_nodes]

    #             # æ£€æŸ¥è¿æ¥æ€§
    #             # è¾¹æ˜¯ prev -> curr
    #             edge_ids = edge_lookup[prev_nodes, curr_nodes]
                
    #             # æœ‰æ•ˆæ¡ä»¶: æ´»è·ƒä¸”æ‰¾åˆ°äº†æœ‰æ•ˆè¾¹ä¸”å‰é©±ä¸æ˜¯ä¸å¯è¾¾(-1)
    #             # æ³¨æ„ï¼šå‡è®¾ P ä¸­ä¸å¯è¾¾æ ‡è®°ä¸º -1 æˆ–å…¶ä»–éæ³•å€¼ï¼Œéœ€æ ¹æ® ws åº“çš„è¡Œä¸ºè°ƒæ•´
    #             # è¿™é‡Œå‡è®¾ edge_lookup ä¼šå¤„ç†éæ³•èŠ‚ç‚¹è¿”å› -1
    #             valid_step = active_mask & (edge_ids != -1) & (prev_nodes != -1)
                
    #             if not valid_step.any():
    #                 # å¦‚æœè¿˜æœ‰æ´»è·ƒçš„ä½†æ‰¾ä¸åˆ°å‰é©±ï¼Œè¯´æ˜è·¯æ–­äº†
    #                 break
                
    #             # è·å–æœ‰æ•ˆç´¢å¼•
    #             # valid_k æ˜¯ commodity çš„ç´¢å¼•
    #             valid_k = torch.nonzero(valid_step, as_tuple=True)[0]
    #             valid_e = edge_ids[valid_step]
                
    #             # ç´¯åŠ æœ¬è½®æµé‡
    #             # æ³¨æ„ index_put_ accumulate=True å¤„ç†å¯èƒ½çš„é‡å¤è¾¹ï¼ˆè™½ç„¶æ­¤æ—¶ valid_k å”¯ä¸€ï¼Œæ‰€ä»¥ç›´æ¥èµ‹å€¼ä¹Ÿå¯ä»¥ï¼‰
    #             x_batch[valid_e, valid_k] += chunk_demands[valid_step]
                
    #             # æ›´æ–°å½“å‰èŠ‚ç‚¹ä¸ºå‰é©±èŠ‚ç‚¹ï¼Œç»§ç»­å›æº¯
    #             curr_nodes[valid_step] = prev_nodes[valid_step]

    #         # D. ç´¯åŠ åˆ°æ€»æµé‡
    #         x_total += x_batch
            
    #         # è°ƒè¯•æ‰“å°ï¼Œç¡®è®¤ x_total ä¸ä¸º 0
    #         if b == 0 and x_total.sum() == 0:
    #             print("Warning: Batch 0 produced zero flow. Path reconstruction might be failing.")

    #         # E. æ‹¥å¡æ„ŸçŸ¥æ›´æ–°
    #         if b < batches - 1:
    #             edge_flow_sum = x_total.sum(dim=1)
    #             # ä½¿ç”¨å½“å‰å·²è·¯ç”±çš„æ‰¹æ¬¡æ¯”ä¾‹æ¥å½’ä¸€åŒ–å®¹é‡ï¼Œæˆ–è€…ç›´æ¥ç”¨æ€»å®¹é‡ï¼ˆMWUé€šå¸¸ç”¨æ€»å®¹é‡ï¼‰
    #             # è¿™é‡Œ x_total æ˜¯ç´¯ç§¯æµé‡ï¼Œcapacities æ˜¯æ€»å®¹é‡
    #             # éšç€ batch å¢åŠ ï¼Œx_total å¢å¤§ï¼Œcongestion å¢å¤§ï¼Œæƒ©ç½šå¢å¤§
    #             congestion = edge_flow_sum / (capacities + 1e-6)
                
    #             # penalty_factor = 1.0 + 5.0 * torch.pow(congestion, 2)
    #             overload = torch.relu(congestion - 1.0) # åªæƒ©ç½šè¶…è¿‡ 1.0 çš„éƒ¨åˆ†
    #             penalty_factor = 1.0 + 2.0 * overload   # çº¿æ€§æƒ©ç½š
    #             current_edge_weights = base_cost * penalty_factor
    #             current_edge_weights = torch.max(current_edge_weights, base_cost)

    #     x_final = x_total * 0.9
    #     X_final = demands * 0.9

    #     # Dual åˆå§‹åŒ–
    #     # Y[u, k] ~ dist(u, k_dst)
    #     # åŒæ ·æ³¨æ„ k_dst æ˜¯ vector
    #     # D shape (N, N). D[:, k_dst] é€‰å–ç›®æ ‡åˆ—
    #     # ä½† k_dst æ˜¯ (K,)ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸ª commodity k å–å‡º D[:, k_dst[k]]
    #     # ç»“æœåº”ä¸º (N, K)
    #     Y_matrix = last_D[:, k_dst] # type: ignore
        
    #     finite_mask = torch.isfinite(Y_matrix)
    #     if finite_mask.any():
    #         max_val = Y_matrix[finite_mask].max()
    #         Y_matrix = torch.where(finite_mask, Y_matrix, max_val * 2.0)
    #     else:
    #         Y_matrix = torch.zeros_like(Y_matrix)
        
    #     return x_final.reshape(-1), X_final, Y_matrix.reshape(-1)


    def _generate_mwu_warm_start(self, batches=10):
        device = self.device
        dtype = self.dtype
        K, M, N = self.K, self.M, self.N
        
        k_src, k_dst = self.k_src, self.k_dst
        demands, capacities = self.d, self.c
        base_cost = self.p 
        
        # [ä¼˜åŒ–1] é¢„åˆ†é…ç»“æœå®¹å™¨
        x_total = torch.zeros((M, K), dtype=dtype, device=device)
        
        # [ä¼˜åŒ–2] ç¼“å­˜è¾¹çš„è´Ÿè½½ (M,)ï¼Œé¿å…æ¯è½®å¯¹ (M, K) åš sum(dim=1)
        # ç”¨ float32 ç´¯åŠ é˜²æ­¢æº¢å‡ºç²¾åº¦é—®é¢˜ï¼Œæœ€åå†è½¬å› dtype
        current_edge_loads = torch.zeros(M, dtype=torch.float32, device=device) 
        current_edge_weights = base_cost.clone()
        
        # é¢„è®¡ç®—æ¯è½®æµé‡
        chunk_demands = demands / batches

        # Edge lookup: (N, N) -> edge_index
        edge_lookup = torch.full((N, N), -1, dtype=torch.long, device=device)
        edge_lookup[self.edges_src, self.edges_dst] = torch.arange(M, device=device)

        # é¢„åˆ†é… Bufferï¼Œé¿å…å¾ªç¯å†…é‡å¤ malloc
        adj_matrix = torch.full((N, N), float('inf'), dtype=dtype, device=device)
        # adj_matrix.fill_diagonal_(0.0) # æ”¾åˆ°å¾ªç¯é‡Œä¸€èµ·åš

        last_D = None
        if self.W_adj is not None:
            del self.W_adj
            self.W_adj = None

        # å¾ªç¯ä¸å˜é‡ï¼šæºèŠ‚ç‚¹åˆ—è¡¨ä¸éœ€è¦åœ¨å¾ªç¯é‡Œ clone
        # ä½†æˆ‘ä»¬éœ€è¦è¿½è¸ªçš„ curr_nodes ä¼šå˜ï¼Œæ‰€ä»¥åªåœ¨å¾ªç¯å¼€å§‹åˆå§‹åŒ–
        
        # é¢„å…ˆç”Ÿæˆ mask å®¹å™¨
        active_mask_buffer = torch.ones(K, dtype=torch.bool, device=device)

        for b in range(batches):
            # --- A. é‡å»ºé‚»æ¥çŸ©é˜µ ---
            # ç›´æ¥èµ‹å€¼ï¼Œæ¯” fill + fill_diagonal ç•¥å¿«ï¼Œåˆ©ç”¨å¹¿æ’­
            adj_matrix.fill_(float('inf'))
            adj_matrix.diagonal().fill_(0.0) 
            adj_matrix[self.edges_src, self.edges_dst] = current_edge_weights

            # --- B. è¿è¡Œ APSP ---
            # å‡è®¾è¿”å› (Distance, Predecessors, _)
            # P[src, dst] = predecessor of dst on path from src
            D, P, _ = ws.parallel_bellman_ford_gpu(adj_matrix, dtype=dtype)
            last_D = D

            # --- C. è·¯å¾„è¿½è¸ª (åå‘å›æº¯: DST -> SRC) ---
            # é‡ç½®è¿½è¸ªçŠ¶æ€
            curr_nodes = k_dst.clone() 
            active_mask_buffer.fill_(True)
            active_mask = active_mask_buffer # å¼•ç”¨

            # æå–å½“å‰æ‰¹æ¬¡çš„éœ€æ±‚é‡ (é¿å…å¾ªç¯å†…ç´¢å¼•)
            # chunks = chunk_demands # ä¹Ÿæ˜¯ Tensor (K,)

            for _ in range(N):
                # 1. æ£€æŸ¥æ˜¯å¦æŠµè¾¾æºç‚¹ (åŸåœ°æ“ä½œå‡å°‘å†…å­˜å¼€é”€)
                # arrived = (curr_nodes == k_src)
                # active_mask &= (~arrived)
                # ä¼˜åŒ–å†™æ³•ï¼šä»…å¯¹ active çš„è¿›è¡Œæ£€æŸ¥
                
                # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šå¦‚æœæ˜¯ active ä¸” node == srcï¼Œåˆ™è®¾ä¸º inactive
                # ä½¿ç”¨ where æˆ–è€… ç›´æ¥ç´¢å¼•æ›´æ–°
                reached_src = (curr_nodes == k_src)
                active_mask.masked_fill_(reached_src, False)

                if not active_mask.any():
                    break
                
                # 2. æŸ¥æ‰¾å‰é©±èŠ‚ç‚¹ P[k_src, curr_nodes]
                # åªéœ€è®¡ç®— active éƒ¨åˆ†ï¼Œå‡å°‘ç´¢å¼•å¼€é”€
                # ä½†ä¸ºäº†åˆ©ç”¨ P çš„è¿ç»­å†…å­˜ï¼Œå…¨é‡ç´¢å¼•å¯èƒ½æ¯” mask åç´¢å¼•æ›´å¿«ï¼ˆå–å†³äº K å¤§å°ï¼‰
                # è¿™é‡Œä¿æŒå…¨é‡ç´¢å¼•ï¼Œä½†åœ¨ edge_ids å¤„è¿‡æ»¤
                prev_nodes = P[k_src, curr_nodes]

                # 3. æŸ¥æ‰¾è¾¹ ID
                edge_ids = edge_lookup[prev_nodes, curr_nodes]
                
                # 4. ç¡®å®šæœ‰æ•ˆæ­¥
                # valid_step = active_mask & (edge_ids != -1) & (prev_nodes != -1)
                # è¿™é‡Œ P ä¸º -1 æ„å‘³ç€ä¸å¯è¾¾ (å‡è®¾wsåº“è¡Œä¸º)
                # ç»„åˆåˆ¤æ–­é€»è¾‘ï¼Œå‡å°‘ä¸­é—´å˜é‡
                valid_step = active_mask & (edge_ids >= 0) & (prev_nodes >= 0)

                if not valid_step.any():
                    break
                
                # 5. [æ ¸å¿ƒä¼˜åŒ–] ç›´æ¥ç´¯åŠ åˆ° x_total å’Œ current_edge_loads
                # é¿å…åˆ›å»º temp_x_batch
                
                # è·å– indices
                valid_k_indices = torch.nonzero(valid_step, as_tuple=True)[0]
                valid_e_indices = edge_ids[valid_step]
                flow_values = chunk_demands[valid_step]

                # æ›´æ–°æ€»æµçŸ©é˜µ (ä½¿ç”¨ index_put_ accumulate=True)
                # x_total[valid_e_indices, valid_k_indices] += flow_values
                x_total.index_put_((valid_e_indices, valid_k_indices), flow_values, accumulate=True)

                # [ä¼˜åŒ–ç‚¹] åŒæ­¥æ›´æ–°è¾¹è´Ÿè½½ç¼“å­˜ï¼Œé¿å… step F çš„ sum(dim=1)
                # current_edge_loads[valid_e_indices] += flow_values
                current_edge_loads.index_put_((valid_e_indices,), flow_values.float(), accumulate=True)

                # 6. ç§»åŠ¨èŠ‚ç‚¹
                curr_nodes[valid_step] = prev_nodes[valid_step]

            # --- D. æ‹¥å¡æ„ŸçŸ¥æ›´æ–° (MWU) ---
            if b < batches - 1:
                # [ä¼˜åŒ–] ç›´æ¥ä½¿ç”¨ç¼“å­˜çš„ edge_loadsï¼Œå¤æ‚åº¦ O(M) è€Œé O(M*K)
                # congestion = current_edge_loads / (capacities + 1e-6)
                
                # åˆå¹¶è®¡ç®—æ­¥éª¤å‡å°‘ kernel launches
                # penalty = 1.0 + 2.0 * relu(load/cap - 1.0)
                # weight = base * penalty
                
                # åˆ©ç”¨ JIT friendly çš„å†™æ³• (è™½ç„¶è¿™é‡Œæ²¡å¼€ JIT)
                congestion_ratio = current_edge_loads / (capacities + 1e-6)
                overload = torch.relu_(congestion_ratio - 1.0) # In-place relu
                
                # å‘é‡åŒ–è®¡ç®—æ–°æƒé‡
                penalty_factor = overload # å¤ç”¨å†…å­˜
                penalty_factor.mul_(2.0).add_(1.0) # 1 + 2 * overload
                
                # update weights
                current_edge_weights = base_cost * penalty_factor
                # ç¡®ä¿æ•°å€¼ç¨³å®šæ€§ (max æ˜¯å¿…è¦çš„ï¼Œè™½ç„¶ç†è®ºä¸Š penalty >= 1)
                current_edge_weights.max(base_cost) 

        # --- E. ç»“æœç»„è£… ---
        x_final = x_total.mul_(0.9) # In-place mul
        X_final = demands * 0.9

        # --- F. Dual åˆå§‹åŒ– ---
        # ç¡®ä¿ last_D å­˜åœ¨
        if last_D is None: 
            # Fallback for batches=0 case
             D, _, _ = ws.parallel_bellman_ford_gpu(adj_matrix, dtype=dtype)
             last_D = D
             
        # Y[u, k] ~ dist(u, k_dst)
        # last_D: (N, N), k_dst: (K,)
        # result: (N, K)
        Y_matrix = last_D[:, k_dst] 
        
        # å¤„ç† Inf
        finite_mask = torch.isfinite(Y_matrix)
        if finite_mask.any():
            max_val = Y_matrix[finite_mask].max()
            # ä½¿ç”¨ where å¡«å……
            Y_matrix = torch.where(finite_mask, Y_matrix, max_val * 2.0)
        else:
            Y_matrix.zero_()
        
        return x_final.reshape(-1), X_final, Y_matrix.reshape(-1)
